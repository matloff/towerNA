
---
title: "Quick Start"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# <span style="color:blue">toweranNA</span>


A **nonimputational**  method for handling missing values (MVs) 
specifically for **prediction applications.** 

*Norm Matloff (UC Davis) and Pete Mohanty (Google)*

<br>
<br>

# Overview: the Goal Is Prediction, Not Statistical Inference

**The intended class of applications is predictive modeling, rather than
estimation.**  Predictive methods of any type can be used with our Tower
Method, including both linear/generalized linear models and
nonparametric/machine learning methods. 

*Notation*  We have a dataset in which one of the columns, Y, is to be
predicted in the future.  The remaining columns, collectively referred
to as X, are the predictor variables/features.

Most of the MV literature, both in the statistics and machine learning
realms, concerns estimation of some relationship,  say estimation of
linear regression coefficients and the like.  By constrast, our emphasis here
is on **PREDICTION**, especially relevant in our AI era.  The main
contribution of this package is a technique that we call the Tower
Method, which is **directly aimed at prediction**. It is
nonimputational, i.e. we do not make guesses as to the missing values in
X.

Note carefully:

* In describing our methods as being for regression applications, *we do
  NOT mean imputing missing values through some regression technique*;
again, our technique is non-imputational.  Instead, our context is that
of regression applications themselves, with the goal being direct
prediction of Y.  

* The term *regression function* does not necessarily imply a linear
  model.  It could also be, say, a logistic model, random forests, etc.

# Usage

The main call form is

``` r
toweranNA(x, fittedReg, k, newx) 
```

where the arguments are: 

* **x**: The X data for the intact rows in the training set. 

* **fittedReg**: The vector of previously fitted regression function values,
i.e. estimated E(Y | X), parameter or nonparametric, over that set. 

* **k**, The number of nearest neighbors. 

* **newx**: The X data to be predicted.  

The number of neighbors is of course a tuning parameter chosen by the
analyst.  Since we are averaging fitted regression estimates, which are
by definition already smoothed, a small value of **k** should work well.  

## Example:  Vocabulary acquisition

This data is from the [Stanford University Wordbank project](http://wordbank.stanford.edu).  The data,
**english**, is included in the <strong>toweranNA</strong> package
(inherited from the included **regtools** package).  Of
the non-administrative variables, e.g. excluding 'Language', which is
always English in this data, about 43 percent of the values are missing.
To illustrate how fitting and prediction occur, let's fit to the intact
observations and then predict Y for the cases having missing values:

``` r
data(english,package='regtools')
# for simplicity:
english1 <- english[,c('age','sex','vocab')]
head(english1)
# age    sex vocab
#  24 Female   337
#  19 Female   384
#  24   Male    76
#  18   Male    19
#  24 Female   480
#  19 Female   313

# make numeric for near neighbor compa
english1$sex <- as.integer(english1$sex == 'Female')

# get the intact rows, fit reg model
eng1 <- na.exclude(english1)
lmout <- lm(vocab ~ .,eng1)
fittedValues <- lmout$fitted.values

# predict vocab for a new case, age 28, female, 5 near neighbors
newx <- data.frame(age=28,sex=1)
toweranNA(eng1,fittedValues,5,newx,scaleX=FALSE)
# outputs 490.7388
newx <- data.frame(age=NA,sex=1)
toweranNA(eng1,fittedValues,5,newx,scaleX=FALSE)
# 400.2152
newx <- data.frame(age=28,sex=NA)
toweranNA(eng1,fittedValues,5,newx,scaleX=FALSE)
# 474.8641

```

# toweranNA: A Method Based on Regression Averaging

## Motivating example

Consider a Census dataset on programmer and engineer Wage, with
predictors Age, Education, Occupation, Gender and Weeks Worked. Say we
need to predict a case in which age and gender are missing.  Then our
prediction might be the estimated value of the regression function of
wage on Education, Occupation and Weeks Worked, i.e. the *marginal
regression function* of wage on those variables.

Since each new case to be predicted will likely have a different
pattern of which variables are missing, we would need to estimate many
(potentially 2<sup>p</sup>) marginal regression functions. This would
in many applications be computationally infeasible, as each marginal
model would need to be fitted and run through diagnostic plots,
hyperparameter investigation, and the like.

**But the Tower Property provides an alternative.**  It tells us that **we can
obtain the marginal regression functions from the full one.**  

## The Tower Property

There is a theorem in abstract probability theory, that says for 
random variables Y, U and V, 

``` 
   E[ E(Y|U,V) | U ] = E(Y | U) 
``` 

Though abstract, it is intuitive.  Say Y, U and V above are Wage,
Gender and Occupation.  E(Y|U,V) is the mean wage among all workers 
of a given gender, in a given occupation.  If we average that quantity
over men and women, but still keep occupation fixed, we obtain the mean
wage in that occupation.
 
In terms of regression functions, this says that if we take the regression
function of Y on U and V, and average it over V for fixed U, we get the
regression function of Y on U.  If V is missing but U is known, this is
very useful, as we will now explain.  

## How it solves our problem:

In the example above, for a new case in which Education,
Occupation and Weeks Worked are known while Age and Gender are missing,
we would have

```
U  = (Education,Occupation,Weeks Worked)
V = (Age,Gender)
```

E(Y|U) is the target marginal regression function that we wish to
estimate and then use to predict the new case in hand.  The Tower
Property implies that we can obtain that estimate by the averaging
process described above.

Specifically, we fit the full model to the complete cases in the data,
then average that model over all data points whose values for Education,
Occupation and Weeks Worked match those in the new case to be predicted.
Thus only the full model need be estimated, rather than 2<sup>p</sup>
models.

Our function **toweranNA()** ("tower analysis with NAs") takes this
approach.  Usually, there may not be many data points having the exact
value specified for U, if any, so we average over a neighborhood of
points near that value.  

Moreover, an early *Biometrika* paper by one of us (summarized in
(Matloff, 2017, Sec. 7.5)) showed that regression averaging improves
estimation of means, even with no MVs, thus an added bonus. 

# Application to Time Series

One can handle missing values in a time series, by
converting to a data frame, then applyng Tower.

## Example:  Gold time series 

Rob Hyndman's **forecast** package includes a time series **gold**,
consisting of 1108 daily gold prices.   The series does have some NAs,
including two in the final 10 data points:

``` r
> gold[1099:1108]
 [1] 395.30 394.10 393.40 396.00     NA     NA 391.25 383.30 384.00 382.30
```
Let's predict the 1109th data point, using the Tower Method:

``` r
gx <- regtools::TStoX(gold,10)
dim(gx)
# 1098   11
# row i contains gx[i], gx[i+1,...,gx[i+10]
gxd <- as.data.frame(gx)
gxdcc <- gxd[complete.cases(gxd),]
lmout <- lm(V11 ~ .,data=gxd)
fits <- lmout$fitted.values 
x1109 <- gold[1099:1108]  # X for predictig gold[1109]
x1109 <- matrix(x1109,nrow=1)
toweranNA(gxdcc,fits,5,x1109)
# 383.0053
```

The function **TStoX()**, which the package imports from **regtools**,
transforms the data to an 11-column matrix, designed for analysis of lag 10.  
In each row of **gx**, we see a value in column 11, preceded in the
row by the 10 most recent points.  That 11th column is the original time
series, minus the first 10 observations.  So, the call to **lm()** is
loosely autoregressive, with each time point predicted from the previous
10.

# Wrapper functions

The package includes functions **towerLM()** and **towerTS()** to wrap
the several operations seen in the worked examples above, e.g.
extracting the complete cases.

# Assumptions

Compared to the widely-used  packages **Amelia** and **mice**,
**toweranNA** has far less restrictive assumptions.  E.g. **Amelia**
assumes multivariate normality of the X vector, an assumption not even
approximately met when some components of X are categorical variables.
Both of those packages make the standard Missing at Random (MAR)
assumption.

In our Tower Method, the assumption involves Y:

E(Y | U, V<sub>NA</sub>) = E(Y | U)

where V<sub>NA</sub> is a boolean variable symbolizing that the variables in 
V are missing.

This assumption is neither implies nor is implied by MAR, but it is
similar to that condition.  As with MAR, this assumption is not
verifiable, and thus we must simply ask, ``Does it work?'', meaning
looking at how well it predicts new cases.


# Reference

N. Matloff, Statistical Regression and Classification: from Linear
Models to Machine Learning, 2017, CRC Press; summarizing N. Matloff,
Use of Regression Functions for Improved Estimation of Means,
*Biometrika*, 1981

